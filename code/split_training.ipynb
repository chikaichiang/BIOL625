{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def split_dataset_by_organism_and_sequence_fraction(\n",
        "    csv_path, test_frac=0.3, random_state=42,\n",
        "    train_out='train_dataset.csv', test_out='test_dataset.csv'\n",
        "):\n",
        "\n",
        "    \"\"\"\n",
        "    Splits a dataset into training and test sets such that:\n",
        "    - No organism appears in both sets.\n",
        "    - The test set includes approximately `test_frac` of total sequences.\n",
        "\n",
        "    Parameters:\n",
        "    - csv_path: Path to the input CSV file.\n",
        "    - test_frac: Fraction of sequences to include in the test set.\n",
        "    - random_state: Seed for reproducibility.\n",
        "    - train_out: Path to save the training CSV.\n",
        "    - test_out: Path to save the test CSV.\n",
        "\n",
        "    Returns:\n",
        "    - train_set, test_set: DataFrames of the training and test splits.\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.read_csv(csv_path)\n",
        "    rng = np.random.default_rng(random_state)\n",
        "\n",
        "    # Count sequences per organism\n",
        "    organism_counts = df['organism'].value_counts().reset_index()\n",
        "    organism_counts.columns = ['organism', 'count']\n",
        "    organism_counts = organism_counts.sample(frac=1, random_state=random_state)  # Shuffle\n",
        "\n",
        "    total_sequences = len(df)\n",
        "    test_organisms = []\n",
        "    running_total = 0\n",
        "\n",
        "    # Accumulate organisms until close to desired test fraction\n",
        "    for _, row in organism_counts.iterrows():\n",
        "        if running_total >= test_frac * total_sequences:\n",
        "            break\n",
        "        test_organisms.append(row['organism'])\n",
        "        running_total += row['count']\n",
        "\n",
        "    # Split based on selected organisms\n",
        "    test_set = df[df['organism'].isin(test_organisms)].copy()\n",
        "    train_set = df[~df['organism'].isin(test_organisms)].copy()\n",
        "\n",
        "    # Save\n",
        "    train_set.to_csv(train_out, index=False)\n",
        "    test_set.to_csv(test_out, index=False)\n",
        "\n",
        "    print(f\"âœ… Train set: {len(train_set)} rows, {train_set['organism'].nunique()} organisms\")\n",
        "    print(f\"âœ… Test set:  {len(test_set)} rows, {test_set['organism'].nunique()} organisms\")\n",
        "    print(f\"ðŸŽ¯ Target test fraction: {test_frac:.2f} | Actual: {len(test_set)/total_sequences:.2f}\")\n",
        "\n",
        "    return train_set, test_set\n",
        "\n"
      ],
      "metadata": {
        "id": "Fz7kQYSE_aFl"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def split_by_id_reference(full_data_path, train_id_path, id_column='ID',\n",
        "                          train_out='train_features.csv', test_out='test_features.csv'):\n",
        "    \"\"\"\n",
        "    Splits full dataset into train/test sets based on IDs found in a reference train set.\n",
        "\n",
        "    Parameters:\n",
        "    - full_data_path: CSV with the full dataset containing an 'ID' column.\n",
        "    - train_id_path: CSV with the reference training set to extract IDs.\n",
        "    - id_column: The name of the ID column (default 'ID').\n",
        "    - train_out: Path to save training split.\n",
        "    - test_out: Path to save testing split.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load full feature dataset and ID reference file\n",
        "    full_df = pd.read_csv(full_data_path)\n",
        "    train_ids = pd.read_csv(train_id_path)[id_column].unique()\n",
        "\n",
        "    # Split based on ID presence\n",
        "    train_df = full_df[full_df[id_column].isin(train_ids)].copy()\n",
        "    test_df = full_df[~full_df[id_column].isin(train_ids)].copy()\n",
        "\n",
        "    # Save results\n",
        "    train_df.to_csv(train_out, index=False)\n",
        "    test_df.to_csv(test_out, index=False)\n",
        "\n",
        "    print(f\"âœ… Training features saved to: {train_out} ({len(train_df)} rows)\")\n",
        "    print(f\"âœ… Testing features saved to: {test_out} ({len(test_df)} rows)\")\n",
        "    return train_df, test_df\n"
      ],
      "metadata": {
        "id": "0TX8qerxF1It"
      },
      "execution_count": 93,
      "outputs": []
    }
  ]
}