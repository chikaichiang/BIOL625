{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "def compute_sample_weights(df, label_col='label', taxa_col='taxa', meiosis_taxa=None):\n",
        "    \"\"\"\n",
        "    Compute sample weights based on label and optionally taxa for meiosis proteins.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): DataFrame containing the data.\n",
        "        label_col (str): Name of the label column ('Meiosis' vs. 'Non-meiosis').\n",
        "        taxa_col (str): Name of the column with taxonomic group info.\n",
        "        meiosis_taxa (list or set): Taxa considered for upweighting (e.g., fungi, plants).\n",
        "\n",
        "    Returns:\n",
        "        pd.Series: Sample weights aligned with df rows.\n",
        "    \"\"\"\n",
        "    if meiosis_taxa is None:\n",
        "        meiosis_taxa = {'chordates', 'arthropods', 'fungi', 'plants', 'other animals'}\n",
        "\n",
        "    weights = []\n",
        "    n_non_meiosis = len(df[df[label_col] == 0])\n",
        "    n_meiosis = len(df[df[label_col] == 1])\n",
        "    global_weight = n_non_meiosis / n_meiosis  # global class weight\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        if row[label_col] == 1 and row[taxa_col] in meiosis_taxa:\n",
        "            weights.append(global_weight)\n",
        "        else:\n",
        "            weights.append(1.0)\n",
        "\n",
        "    return pd.Series(weights, index=df.index)"
      ],
      "metadata": {
        "id": "FzLjHPWaVY1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6D9OG09qSFQb"
      },
      "outputs": [],
      "source": [
        "# Best parameters from the trained model recorded\n",
        "best_params = {\n",
        "    'hidden_dim': 128,\n",
        "    'dropout': 0.3,\n",
        "    'lr': 0.001,\n",
        "    'batch_size': 32,\n",
        "    'num_layers': 2,\n",
        "    'activation': 'relu',\n",
        "    'weight_decay': 0,\n",
        "    'optimizer': 'adamW'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "# uploaded=files.upload()"
      ],
      "metadata": {
        "id": "WXfsoFjMcAXo"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# uploaded=files.upload()"
      ],
      "metadata": {
        "id": "vhZ_QaKgcON8"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ---- 1. Sample Weight Function ----\n",
        "def compute_sample_weights(df, label_col='label', taxa_col='taxa', meiosis_taxa=None):\n",
        "    \"\"\"\n",
        "    Compute sample weights to handle class imbalance, upweighting known meiosis taxa.\n",
        "    \"\"\"\n",
        "    if meiosis_taxa is None:\n",
        "        meiosis_taxa = {'chordates', 'arthropods', 'fungi', 'plants', 'other animals'}\n",
        "\n",
        "    n_non_meiosis = len(df[df[label_col] == 0])\n",
        "    n_meiosis = len(df[df[label_col] == 1])\n",
        "    global_weight = n_non_meiosis / n_meiosis  # Upweight positive samples\n",
        "\n",
        "    weights = []\n",
        "    for _, row in df.iterrows():\n",
        "        if row[label_col] == 1 and row[taxa_col] in meiosis_taxa:\n",
        "            weights.append(global_weight)\n",
        "        else:\n",
        "            weights.append(1.0)\n",
        "\n",
        "    return pd.Series(weights, index=df.index)\n",
        "\n",
        "# ---- 2. Load Training Data ----\n",
        "df_train = pd.read_csv(\"mrmr_selected_train_spo11_aa_50.csv\")\n",
        "X_train = df_train.iloc[:, 1:-2].values\n",
        "y_train = df_train['label'].values\n",
        "taxa_train = df_train['taxa'].values\n",
        "\n",
        "# Compute sample weights\n",
        "sample_weights_series = compute_sample_weights(df_train, label_col='label', taxa_col='taxa')\n",
        "sample_weights = torch.tensor(sample_weights_series.values, dtype=torch.float32)\n",
        "\n",
        "# ---- 3. Torch Dataset ----\n",
        "class ProteinDataset(Dataset):\n",
        "    def __init__(self, X, y, weights):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "        self.weights = weights\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx], self.weights[idx]\n",
        "\n",
        "# ---- 4. MLP Model ----\n",
        "class MLPClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers, dropout, activation):\n",
        "        super(MLPClassifier, self).__init__()\n",
        "        layers = [nn.Linear(input_dim, hidden_dim)]\n",
        "        act = getattr(nn, activation)() if hasattr(nn, activation) else nn.ReLU()\n",
        "        for _ in range(num_layers - 1):\n",
        "            layers += [act, nn.Dropout(dropout), nn.Linear(hidden_dim, hidden_dim)]\n",
        "        layers += [act, nn.Dropout(dropout), nn.Linear(hidden_dim, 2)]\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# ---- 5. Model Setup ----\n",
        "best_params = {\n",
        "    'hidden_dim': 128, #\n",
        "    'dropout': 0.3,\n",
        "    'num_layers': 2,\n",
        "    'activation': 'ReLU',\n",
        "    'lr': 0.001,\n",
        "    'weight_decay': 0.0001,\n",
        "    'batch_size': 32\n",
        "}\n",
        "\n",
        "model = MLPClassifier(\n",
        "    input_dim=X_train.shape[1],\n",
        "    hidden_dim=best_params['hidden_dim'],\n",
        "    dropout=best_params['dropout'],\n",
        "    num_layers=best_params['num_layers'],\n",
        "    activation=best_params['activation']\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=best_params['lr'], weight_decay=best_params['weight_decay'])\n",
        "criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "\n",
        "train_dataset = ProteinDataset(X_train, y_train, sample_weights)\n",
        "train_loader = DataLoader(train_dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
        "\n",
        "# ---- 6. Training Loop ----\n",
        "n_epochs = 50\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_x, batch_y, batch_weights in train_loader:\n",
        "        batch_x, batch_y, batch_weights = batch_x.to(device), batch_y.to(device), batch_weights.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_x)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        weighted_loss = (loss * batch_weights).mean()\n",
        "        weighted_loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += weighted_loss.item()\n",
        "#    print(f\"Epoch {epoch+1}/{n_epochs} - Loss: {total_loss:.4f}\")"
      ],
      "metadata": {
        "id": "0ctya2BzStfI"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- 7. Predict Protist Candidates ---- entamoeba, trypanosoma, plasmodium\n",
        "threshold = 0.95  # Set your desired confidence threshold\n",
        "\n",
        "df_protist = pd.read_csv(\"selected_spo11_entamoeba_50.csv\")\n",
        "protist_ids = df_protist.iloc[:, 0].values\n",
        "X_protist = df_protist.iloc[:, 1:].values\n",
        "X_protist_tensor = torch.tensor(X_protist, dtype=torch.float32).to(device)\n",
        "\n",
        "model.eval()\n",
        "# with torch.no_grad():\n",
        "#     logits = model(X_protist_tensor)\n",
        "#    probs = torch.softmax(logits, dim=1)[:, 1].cpu().numpy()  # Probability of class 1 (meiosis)\n",
        "\n",
        "# Apply custom threshold to assign labels\n",
        "# preds = (probs >= threshold).astype(int)\n",
        "\n",
        "# Save results\n",
        "# df_results = pd.DataFrame({\n",
        "#    \"ID\": protist_ids,\n",
        "#    \"PredictedLabel\": preds,\n",
        "#    \"MeiosisProbability\": probs\n",
        "#})\n",
        "\n",
        "# df_results.to_csv(\"protist_spo11_entamoeba_50_predictions_mlp.csv\", index=False)\n",
        "\n",
        "# Save top-scoring predictions, regardless of threshold\n",
        "# df_results.sort_values(\"MeiosisProbability\", ascending=False).head(50).to_csv(\"top_spo11_trypanosoma_hits_mlp_50.csv\", index=False)\n",
        "\n",
        "# print(f\"âœ… Protist scan complete with threshold {threshold}. Results saved.\")\n",
        "# print(f\"Number of predicted meiosis proteins: {(preds == 1).sum()}\")\n"
      ],
      "metadata": {
        "id": "PYP4EKxPddzx"
      },
      "execution_count": 201,
      "outputs": []
    }
  ]
}