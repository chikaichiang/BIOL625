{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from scipy.stats import spearmanr\n",
        "from google.colab import files\n",
        "\n",
        "# mRMR approximation function\n",
        "def approximate_mrmr(X, y, feature_groups, n_clusters=50, top_k=100):\n",
        "\n",
        "    \"\"\"\n",
        "    Approximates the Minimum Redundancy Maximum Relevance (mRMR) feature selection method by:\n",
        "    - Reducing intra-group redundancy using hierarchical clustering based on Spearman correlation.\n",
        "    - Selecting one representative feature per cluster using mutual information (MI) with the target.\n",
        "    - Ranking selected features globally using MI and returning the top-k most informative features.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : ndarray of shape (n_samples, n_features)\n",
        "        Feature matrix.\n",
        "\n",
        "    y : array-like of shape (n_samples,)\n",
        "        Target labels (e.g., binary classification).\n",
        "\n",
        "    feature_groups : dict\n",
        "        Dictionary mapping group names to lists of feature indices.\n",
        "        These groups represent biologically or functionally meaningful feature blocks (e.g., ESM, AAC, PseAAC).\n",
        "\n",
        "    n_clusters : int, optional (default=50)\n",
        "        Number of clusters for intra-group feature reduction via Agglomerative Clustering.\n",
        "\n",
        "    top_k : int, optional (default=100)\n",
        "        Number of top features to return based on mutual information ranking across all selected features.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    selected_final : list of int\n",
        "        List of indices of the top_k selected features from the original feature matrix.\n",
        "    \"\"\"\n",
        "\n",
        "    n_features = X.shape[1]\n",
        "    for group_name, indices in feature_groups.items():\n",
        "        if max(indices) >= n_features:\n",
        "            raise ValueError(f\"Feature group '{group_name}' contains indices beyond matrix size (max index: {max(indices)}, matrix size: {n_features})\")\n",
        "\n",
        "    selected_features = []\n",
        "\n",
        "    for group_name, indices in feature_groups.items():\n",
        "        X_group = X[:, indices]\n",
        "\n",
        "        if X_group.shape[1] == 1:\n",
        "            selected_features.append(indices[0])\n",
        "            continue\n",
        "\n",
        "        corr_matrix = spearmanr(X_group, axis=0).correlation\n",
        "        corr_dist = 1 - np.abs(corr_matrix)\n",
        "        np.fill_diagonal(corr_dist, 0)\n",
        "\n",
        "        clustering = AgglomerativeClustering(\n",
        "            n_clusters=min(n_clusters, len(indices)),\n",
        "            metric='precomputed',\n",
        "            linkage='complete'\n",
        "        )\n",
        "        clusters = clustering.fit_predict(corr_dist)\n",
        "\n",
        "        mi_scores = mutual_info_classif(X_group, y, random_state=42)\n",
        "\n",
        "        for cluster_id in np.unique(clusters):\n",
        "            cluster_mask = (clusters == cluster_id)\n",
        "            cluster_indices = np.where(cluster_mask)[0]\n",
        "            cluster_mi_scores = mi_scores[cluster_mask]\n",
        "            best_local_idx = cluster_indices[np.argmax(cluster_mi_scores)]\n",
        "            best_feature_idx = indices[best_local_idx]\n",
        "            selected_features.append(best_feature_idx)\n",
        "\n",
        "    mi_scores_global = mutual_info_classif(X[:, selected_features], y)\n",
        "    top_indices = np.argsort(mi_scores_global)[-top_k:]\n",
        "    return [selected_features[i] for i in top_indices]"
      ],
      "metadata": {
        "id": "67DJICiaeURR"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_train_test_feature_selection(train_csv, test_csv, output_train_csv, output_test_csv,\n",
        "                                     feature_groups, n_clusters=50, k_features=50,\n",
        "                                     shannon_index=434):\n",
        "    \"\"\"\n",
        "    Perform feature selection using approximate mRMR on the training dataset,\n",
        "    apply the same selected features to both training and test sets, and save\n",
        "    the reduced feature matrices to new CSV files.\n",
        "\n",
        "    Additionally, ensures Shannon entropy (default index 434) is included in the selected features.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    train_csv : str\n",
        "        Path to the training dataset CSV file. The file must have columns in the order:\n",
        "        [ID, features..., Taxonomic Group, Label]\n",
        "\n",
        "    test_csv : str\n",
        "        Path to the test dataset CSV file. Same column structure as train_csv.\n",
        "\n",
        "    output_train_csv : str\n",
        "        Path to save the transformed training dataset with selected features.\n",
        "\n",
        "    output_test_csv : str\n",
        "        Path to save the transformed test dataset with selected features.\n",
        "\n",
        "    feature_groups : dict\n",
        "        Dictionary mapping group names to lists of feature indices. Used for mRMR approximation.\n",
        "\n",
        "    n_clusters : int, optional (default=50)\n",
        "        Number of clusters to use for intra-group feature redundancy reduction.\n",
        "\n",
        "    k_features : int, optional (default=50)\n",
        "        Number of top features to select from the entire set of groups after mRMR scoring.\n",
        "\n",
        "    shannon_index : int, optional (default=434)\n",
        "        Index of the Shannon entropy feature to include even if it's not selected by mRMR.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    None\n",
        "    \"\"\"\n",
        "\n",
        "    # Load datasets\n",
        "    df_train = pd.read_csv(train_csv)\n",
        "    df_test = pd.read_csv(test_csv)\n",
        "\n",
        "    # Extract features and metadata from training set\n",
        "    X_train = df_train.iloc[:, 1:-2].values\n",
        "    y_train = df_train.iloc[:, -1].values\n",
        "    train_ids = df_train.iloc[:, 0]\n",
        "    train_taxa = df_train.iloc[:, -2]\n",
        "    train_labels = df_train.iloc[:, -1]\n",
        "\n",
        "    # Extract test set features and metadata\n",
        "    X_test = df_test.iloc[:, 1:-2].values\n",
        "    test_ids = df_test.iloc[:, 0]\n",
        "    test_taxa = df_test.iloc[:, -2]\n",
        "    test_labels = df_test.iloc[:, -1]\n",
        "\n",
        "    # Run approximate mRMR feature selection on training data\n",
        "    selected_indices = approximate_mrmr(X_train, y_train, feature_groups, n_clusters, k_features)\n",
        "\n",
        "    # Ensure Shannon entropy is included\n",
        "    if shannon_index not in selected_indices:\n",
        "        selected_indices.append(shannon_index)\n",
        "\n",
        "    # Get corresponding column names for selected features\n",
        "    selected_feature_names = [df_train.columns[1:-2][i] for i in selected_indices]\n",
        "\n",
        "    # Create new DataFrames with selected features + metadata\n",
        "    df_train_selected = pd.concat([train_ids, df_train[selected_feature_names], train_taxa, train_labels], axis=1)\n",
        "    df_test_selected = pd.concat([test_ids, df_test[selected_feature_names], test_taxa, test_labels], axis=1)\n",
        "\n",
        "    # Save to output CSV files\n",
        "    df_train_selected.to_csv(output_train_csv, index=False)\n",
        "    df_test_selected.to_csv(output_test_csv, index=False)\n",
        "\n",
        "    print(f\"✅ Saved: {output_train_csv} and {output_test_csv} with {len(selected_feature_names)} features.\")\n",
        "    print(f\"Selected features (including Shannon entropy if needed): {selected_feature_names}\")\n"
      ],
      "metadata": {
        "id": "kla0KalHhbqo"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def should_keep_entropy(X, y, entropy_idx):\n",
        "    \"\"\"\n",
        "    Decide whether Shannon Entropy (at a given column index) should be retained as a feature.\n",
        "\n",
        "    This function applies a multi-step filter to assess whether the entropy feature provides\n",
        "    meaningful and non-redundant information for classification tasks. It returns a standard\n",
        "    Python boolean (`True` or `False`) to indicate whether to keep the feature.\n",
        "\n",
        "    Steps:\n",
        "    1. Variance Check:\n",
        "        - If the variance of Shannon Entropy is too small (below 1e-5), it provides no useful signal.\n",
        "        - In that case, discard the feature.\n",
        "\n",
        "    2️. Redundancy Check (Correlation):\n",
        "        - Compute the absolute correlation of Shannon Entropy with all other features.\n",
        "        - If the maximum absolute correlation exceeds 0.9, it is considered highly redundant.\n",
        "        - Discard the feature in that case.\n",
        "\n",
        "    3️. Feature Importance Check (Random Forest):\n",
        "        - Train a quick Random Forest Classifier (50 trees) on the data.\n",
        "        - Compare the feature importance of Shannon Entropy to the median importance of all features.\n",
        "        - If Entropy’s importance is above the median, keep it; otherwise, discard it.\n",
        "\n",
        "    Args:\n",
        "        X (np.ndarray): Feature matrix, shape (n_samples, n_features).\n",
        "        y (np.ndarray): Labels, shape (n_samples,).\n",
        "        entropy_idx (int): Column index of the Shannon Entropy feature in X.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if the feature passes all checks and should be retained, False otherwise.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Variance check: discard if variance too small\n",
        "    entropy_values = X[:, entropy_idx]\n",
        "    if np.var(entropy_values) < 1e-5:\n",
        "        return False\n",
        "\n",
        "    # 2. Correlation (redundancy) check: discard if highly correlated with other features\n",
        "    corr_with_others = np.abs(\n",
        "        np.corrcoef(entropy_values, X[:, np.arange(X.shape[1]) != entropy_idx], rowvar=False)[0, 1:]\n",
        "    ).max()\n",
        "    if corr_with_others > 0.9:\n",
        "        return False\n",
        "\n",
        "    # 3. Feature importance check via Random Forest: discard if below median importance\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    model = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Convert np.bool_ to Python bool explicitly for consistency\n",
        "    return bool(model.feature_importances_[entropy_idx] > np.median(model.feature_importances_))"
      ],
      "metadata": {
        "id": "1QqFHtdMou0D"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2️. Define your feature groups (adjust indices based on your CSV)\n",
        "feature_groups = {\n",
        "    'Dipeptide': range(0, 399),       # X[:, 0:399] → AA (df col 1) to YY (df col 399)\n",
        "    'PseAAC': range(399, 419),        # X[:, 399:419] → AAC_A (df col 400) to AAC_Y (df col 419)\n",
        "    'PseAAC_theta': range(419, 424),  # Theta_1 (df col 420) to Theta_5 (df col 424)\n",
        "    'PhysChem': range(424, 434),      # Avg_Hydrophobicity (df col 425) to Avg_Bulkiness (df col 434)\n",
        "    'Entropy': [434],                 # Shannon_Entropy (df col 435)\n",
        "    'CTD': range(435, 582),           # _PolarizabilityC1 (df col 436) to _HydrophobicityD3100 (df col 582)\n",
        "    'Z-scale': range(582, 587)        # Z1 (df col 583) to Z5 (df col 587)\n",
        "}"
      ],
      "metadata": {
        "id": "w2mGxvWIhpxS"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "phFQiw1rLKKv",
        "outputId": "57468511-7e77-4bad-a717-014a64fcd165"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-18a72139-cba8-4801-b96d-c0e1c9be9a31\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-18a72139-cba8-4801-b96d-c0e1c9be9a31\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving std_train_spo11_aa.csv to std_train_spo11_aa.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "5fE_hItRLRL2",
        "outputId": "09597ffc-8a20-4e2c-8612-36350519db0b"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f2f2194b-71bd-4cd1-ad91-76c968746197\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f2f2194b-71bd-4cd1-ad91-76c968746197\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving std_test_spo11_aa.csv to std_test_spo11_aa.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# File names:\n",
        "train_csv = 'std_train_spo11_aa.csv'\n",
        "test_csv = 'std_test_spo11_aa.csv'\n",
        "output_train_csv = 'mrmr_selected_train_spo11_aa_50.csv'\n",
        "output_test_csv = 'mrmr_selected_test_spo11_aa_50.csv'\n",
        "\n",
        "# 4️. Run it\n",
        "run_train_test_feature_selection(train_csv, test_csv, output_train_csv, output_test_csv,\n",
        "                                 feature_groups, n_clusters=50, k_features=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oe0s5NTXDnt",
        "outputId": "ad900e71-1b95-4d21-f80b-9f6f6a1af423"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved: mrmr_selected_train_spo11_aa_50.csv and mrmr_selected_test_spo11_aa_50.csv with 51 features.\n",
            "Selected features (including Shannon entropy if needed): ['LG', '_ChargeC2', 'RF', '_SecondaryStrD3001', 'AE', '_PolarityD1025', 'KG', '_PolarizabilityD2001', 'IE', 'YK', 'KF', '_PolarityD3100', 'Z4', 'GL', '_ChargeD3100', 'PL', 'VG', '_PolarityD3001', '_HydrophobicityD2100', 'IT', '_SolventAccessibilityD3100', '_SecondaryStrD3100', 'MA', 'RD', 'VP', '_NormalizedVDWVD3100', 'GS', 'TG', 'LS', 'FG', 'AAC_C', 'EE', 'PS', 'Avg_Hydrophobicity', 'TR', 'ML', 'PD', 'DC', 'Z2', 'Avg_Hydrophilicity', 'AAC_L', 'IL', 'Avg_Solvent_Accessibility', 'Z5', 'Z1', 'Avg_Bulkiness', '_PolarizabilityD3001', 'WL', 'Avg_Polarity', '_HydrophobicityC3', 'Shannon_Entropy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# File names:\n",
        "train_csv = 'std_train_spo11_aa.csv'\n",
        "test_csv = 'std_test_spo11_aa.csv'\n",
        "output_train_csv = 'mrmr_selected_train_spo11_aa_100.csv'\n",
        "output_test_csv = 'mrmr_selected_test_spo11_aa_100.csv'\n",
        "\n",
        "# 4️. Run it\n",
        "run_train_test_feature_selection(train_csv, test_csv, output_train_csv, output_test_csv,\n",
        "                                 feature_groups, n_clusters=100, k_features=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoXb5F7wP1kg",
        "outputId": "4d384b63-8d1d-4c3b-d311-20aee48f9956"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved: mrmr_selected_train_spo11_aa_100.csv and mrmr_selected_test_spo11_aa_100.csv with 101 features.\n",
            "Selected features (including Shannon entropy if needed): ['FT', 'VN', 'IF', 'PA', 'IK', 'PG', 'AL', 'Avg_Polarizability', 'FV', 'ME', 'LY', 'GI', 'NI', 'LD', 'RK', 'ND', 'NL', 'AH', 'QL', 'MV', '_ChargeC2', '_ChargeC3', 'LR', 'KD', 'GA', 'GE', 'LA', 'PR', 'GQ', '_PolarizabilityD1075', '_SecondaryStrD1100', 'VQ', 'MG', 'AE', 'IQ', 'LG', 'AD', 'ED', '_PolarityD2100', '_PolarityD1050', 'AP', 'RF', 'RV', '_SecondaryStrD3001', 'YR', '_ChargeD3001', '_SolventAccessibilityD1001', '_PolarityD1025', 'MA', 'IE', 'YK', 'KS', 'KG', '_PolarizabilityD2001', '_PolarizabilityD1100', 'GL', 'Z4', 'VG', '_HydrophobicityD2100', '_PolarityD3001', '_ChargeD3100', 'IT', 'PL', 'KF', 'VP', 'RD', '_SecondaryStrD3100', '_ChargeD1100', '_PolarityD3100', '_SolventAccessibilityD3100', '_HydrophobicityD2001', 'GS', 'FG', '_NormalizedVDWVD3100', '_HydrophobicityT12', 'PS', 'TG', 'LS', 'AAC_C', 'EE', 'Avg_Hydrophobicity', 'ML', 'TR', 'PD', 'LV', 'DC', 'Z2', 'Avg_Hydrophilicity', 'LL', 'AAC_L', 'IL', 'Avg_Solvent_Accessibility', 'Z5', 'Z1', 'YY', 'Avg_Bulkiness', '_PolarizabilityD3001', 'WL', 'Avg_Polarity', '_HydrophobicityC3', 'Shannon_Entropy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('mrmr_selected_train_spo11_aa_50.csv')\n",
        "files.download('mrmr_selected_test_spo11_aa_50.csv')\n",
        "files.download('mrmr_selected_train_spo11_aa_100.csv')\n",
        "files.download('mrmr_selected_test_spo11_aa_100.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Vt43LpQHVeM6",
        "outputId": "2813f62f-de7c-4c1c-e393-4ca8189c0f11"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a5d67177-34f1-4155-b166-25bf0201433f\", \"mrmr_selected_train_spo11_aa_50.csv\", 2149534)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fba2d972-00fb-491f-9b3b-151e69f612bd\", \"mrmr_selected_test_spo11_aa_50.csv\", 922854)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_654678b6-62ee-42c7-bfa9-89c479433d13\", \"mrmr_selected_train_spo11_aa_100.csv\", 4190489)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_49758027-21f2-4d2d-aa40-3d08c2894efe\", \"mrmr_selected_test_spo11_aa_100.csv\", 1798870)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV\n",
        "df = pd.read_csv(train_csv)\n",
        "\n",
        "# Prepare data\n",
        "X = df.iloc[:, 1:-2].values  # Feature matrix (exclude ID, taxa, and label)\n",
        "y = df.iloc[:, -1].values    # Labels (last column assumed to be label)\n",
        "entropy_idx = 434\n",
        "\n",
        "# Run entropy check\n",
        "should_keep_entropy(X, y, entropy_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzvSVadVhHhV",
        "outputId": "28477617-3b4f-4738-8257-e3784915a96f"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the files\n",
        "df_train_50 = pd.read_csv('mrmr_selected_train_spo11_aa_50.csv')\n",
        "df_test_50 = pd.read_csv('mrmr_selected_test_spo11_aa_50.csv')\n",
        "df_train_100 = pd.read_csv('mrmr_selected_train_spo11_aa_100.csv')\n",
        "df_test_100 = pd.read_csv('mrmr_selected_test_spo11_aa_100.csv')\n",
        "\n",
        "# Print dimensions\n",
        "print(\"Train 50 shape:\", df_train_50.shape)\n",
        "print(\"Test 50 shape:\", df_test_50.shape)\n",
        "print(\"Train 100 shape:\", df_train_100.shape)\n",
        "print(\"Test 100 shape:\", df_test_100.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7EfUcbUZIgv",
        "outputId": "c003675a-0082-4fe8-c3bc-123ca218cd3a"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train 50 shape: (2109, 54)\n",
            "Test 50 shape: (905, 54)\n",
            "Train 100 shape: (2109, 104)\n",
            "Test 100 shape: (905, 104)\n"
          ]
        }
      ]
    }
  ]
}