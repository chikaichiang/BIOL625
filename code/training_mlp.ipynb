{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yWEbWlMG-uck"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import itertools\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Automatically use GPU if available, otherwise fall back to CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "FG1BleXx_HqV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_sample_weights(df, label_col='label', taxa_col='taxa', meiosis_taxa=None):\n",
        "    \"\"\"\n",
        "    Compute sample weights based on label and optionally taxa for meiosis proteins.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): DataFrame containing the data.\n",
        "        label_col (str): Name of the label column ('Meiosis' vs. 'Non-meiosis').\n",
        "        taxa_col (str): Name of the column with taxonomic group info.\n",
        "        meiosis_taxa (list or set): Taxa considered for upweighting (e.g., fungi, plants).\n",
        "\n",
        "    Returns:\n",
        "        pd.Series: Sample weights aligned with df rows.\n",
        "    \"\"\"\n",
        "    if meiosis_taxa is None:\n",
        "        meiosis_taxa = {'chordates', 'arthropods', 'fungi', 'plants', 'other animals'}\n",
        "\n",
        "    weights = []\n",
        "    n_non_meiosis = len(df[df[label_col] == 0])\n",
        "    n_meiosis = len(df[df[label_col] == 1])\n",
        "    global_weight = n_non_meiosis / n_meiosis  # global class weight\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        if row[label_col] == 1 and row[taxa_col] in meiosis_taxa:\n",
        "            weights.append(global_weight)\n",
        "        else:\n",
        "            weights.append(1.0)\n",
        "\n",
        "    return pd.Series(weights, index=df.index)\n"
      ],
      "metadata": {
        "id": "G_bSTf-K-5NI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset builder\n",
        "class ProteinDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# MLP model\n",
        "class MLPClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128, dropout=0.3):\n",
        "        super(MLPClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc2 = nn.Linear(hidden_dim, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        return self.fc2(x)"
      ],
      "metadata": {
        "id": "05kKyuSvBrDa"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP model\n",
        "class MLPClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128, num_layers=1, dropout=0.3, activation='relu'):\n",
        "        super(MLPClassifier, self).__init__()\n",
        "        self.activation_fn = getattr(F, activation)\n",
        "        layers = []\n",
        "        layers.append(nn.Linear(input_dim, hidden_dim))\n",
        "        layers.append(nn.Dropout(dropout))\n",
        "        for _ in range(num_layers - 1):\n",
        "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "        self.hidden = nn.Sequential(*layers)\n",
        "        self.output = nn.Linear(hidden_dim, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.hidden:\n",
        "            if isinstance(layer, nn.Linear):\n",
        "                x = self.activation_fn(layer(x))\n",
        "            else:\n",
        "                x = layer(x)\n",
        "        return self.output(x)"
      ],
      "metadata": {
        "id": "2xZ6STDJNtNV"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Introduce class of early stopping\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, delta=0, mode='max'):\n",
        "        self.patience = patience\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.delta = delta\n",
        "        self.mode = mode\n",
        "        self.best_model_state = None\n",
        "\n",
        "    def __call__(self, score, model):\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.best_model_state = model.state_dict()\n",
        "            return\n",
        "        if (self.mode == 'max' and score > self.best_score + self.delta) or \\\n",
        "           (self.mode == 'min' and score < self.best_score - self.delta):\n",
        "            self.best_score = score\n",
        "            self.best_model_state = model.state_dict()\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True"
      ],
      "metadata": {
        "id": "sDpSqtEGNuoA"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tune_mlp_hyperparameters(X, y, sample_weights, param_grid=None, n_splits=10, epochs=20):\n",
        "\n",
        "    \"\"\"\n",
        "    Perform grid search to tune hyperparameters for a multi-layer perceptron (MLP) classifier using cross-validation.\n",
        "\n",
        "    This function explores combinations of hyperparameters for an MLP model on the input dataset\n",
        "    using stratified k-fold cross-validation. It evaluates each model using the F1 score and applies early\n",
        "    stopping to avoid overfitting. The model with the highest average F1 score across folds is returned.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    X : np.ndarray\n",
        "        Feature matrix of shape (n_samples, n_features).\n",
        "\n",
        "    y : np.ndarray\n",
        "        Target labels of shape (n_samples,).\n",
        "\n",
        "    sample_weights : np.ndarray\n",
        "        Sample weights for handling class imbalance during training. Used in the WeightedRandomSampler.\n",
        "\n",
        "    param_grid : dict, optional\n",
        "        Dictionary specifying the hyperparameter search space. Keys are parameter names and values are lists\n",
        "        of possible values. If None, a default grid is used.\n",
        "\n",
        "    n_splits : int, default=10\n",
        "        Number of cross-validation splits (StratifiedKFold).\n",
        "\n",
        "    epochs : int, default=20\n",
        "        Maximum number of training epochs per fold. Early stopping may halt training sooner.\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    best_model : torch.nn.Module\n",
        "        The MLP model trained with the best hyperparameter combination.\n",
        "\n",
        "    best_params : dict\n",
        "        Dictionary of the best-performing hyperparameter settings.\n",
        "\n",
        "    Notes:\n",
        "    -----\n",
        "    - Evaluation is based on the average F1 score over all folds.\n",
        "    - Early stopping is triggered if the F1 score does not improve over 'patience' epochs.\n",
        "    - The function assumes the use of GPU if `device` is set to 'cuda'.\n",
        "    - The model architecture and training behavior are controlled via the param_grid.\n",
        "    \"\"\"\n",
        "\n",
        "    if param_grid is None:\n",
        "        param_grid = {\n",
        "            'hidden_dim': [64, 128],\n",
        "            'dropout': [0.2, 0.3],\n",
        "            'lr': [1e-3, 5e-4],\n",
        "            'batch_size': [32],\n",
        "            'num_layers': [1, 2],\n",
        "            'activation': ['relu'],\n",
        "            'weight_decay': [0, 1e-4],\n",
        "            'optimizer': ['adamW']\n",
        "    }\n",
        "\n",
        "    keys, values = zip(*param_grid.items())\n",
        "    grid = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
        "\n",
        "    best_f1 = -1\n",
        "    best_params = None\n",
        "    best_model = None\n",
        "\n",
        "    for params in grid:\n",
        "        print(f\"\\n🔍 Trying: {params}\")\n",
        "        f1s = []\n",
        "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "        for train_idx, val_idx in skf.split(X, y):\n",
        "            X_train, X_val = X[train_idx], X[val_idx]\n",
        "            y_train, y_val = y[train_idx], y[val_idx]\n",
        "            weights = sample_weights[train_idx]\n",
        "\n",
        "            train_dataset = ProteinDataset(X_train, y_train)\n",
        "            val_dataset = ProteinDataset(X_val, y_val)\n",
        "\n",
        "            sampler = WeightedRandomSampler(weights, len(weights), replacement=True)\n",
        "            train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], sampler=sampler)\n",
        "            val_loader = DataLoader(val_dataset, batch_size=params['batch_size'], shuffle=False)\n",
        "\n",
        "            model = MLPClassifier(\n",
        "                input_dim=X.shape[1],\n",
        "                hidden_dim=params['hidden_dim'],\n",
        "                dropout=params['dropout'],\n",
        "                num_layers=params['num_layers'],\n",
        "                activation=params['activation']\n",
        "            ).to(device)\n",
        "\n",
        "            if params['optimizer'] == 'adam':\n",
        "                optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'], weight_decay=params['weight_decay'])\n",
        "            elif params['optimizer'] == 'sgd':\n",
        "                optimizer = torch.optim.SGD(model.parameters(), lr=params['lr'], weight_decay=params['weight_decay'])\n",
        "            elif params['optimizer'] == 'adamW':\n",
        "                optimizer = torch.optim.AdamW(model.parameters(), lr=params['lr'], weight_decay=params['weight_decay'])\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported optimizer: {params['optimizer']}\")\n",
        "\n",
        "            criterion = torch.nn.CrossEntropyLoss()\n",
        "            early_stopper = EarlyStopping(patience=5, mode='max')\n",
        "\n",
        "            for epoch in range(epochs):\n",
        "                model.train()\n",
        "                for xb, yb in train_loader:\n",
        "                    xb, yb = xb.to(device), yb.to(device)\n",
        "                    optimizer.zero_grad()\n",
        "                    loss = criterion(model(xb), yb)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                model.eval()\n",
        "                y_pred, y_true = [], []\n",
        "                with torch.no_grad():\n",
        "                    for xb, yb in val_loader:\n",
        "                        xb = xb.to(device)\n",
        "                        logits = model(xb)\n",
        "                        pred = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "                        y_pred.extend(pred)\n",
        "                        y_true.extend(yb.numpy())\n",
        "\n",
        "                f1 = f1_score(y_true, y_pred)\n",
        "                early_stopper(f1, model)\n",
        "\n",
        "                if early_stopper.early_stop:\n",
        "                    print(f\"⏹️ Early stopping at epoch {epoch + 1}\")\n",
        "                    break\n",
        "\n",
        "            model.load_state_dict(early_stopper.best_model_state)\n",
        "\n",
        "            model.eval()\n",
        "            y_pred, y_true = [], []\n",
        "            with torch.no_grad():\n",
        "                for xb, yb in val_loader:\n",
        "                    xb = xb.to(device)\n",
        "                    logits = model(xb)\n",
        "                    pred = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "                    y_pred.extend(pred)\n",
        "                    y_true.extend(yb.numpy())\n",
        "\n",
        "            f1 = f1_score(y_true, y_pred)\n",
        "            f1s.append(f1)\n",
        "\n",
        "        avg_f1 = np.mean(f1s)\n",
        "        print(f\"✅ Avg F1: {avg_f1:.4f}\")\n",
        "\n",
        "        if avg_f1 > best_f1:\n",
        "            best_f1 = avg_f1\n",
        "            best_params = params.copy()\n",
        "            best_model = model\n",
        "\n",
        "    print(f\"\\n🎯 Best params: {best_params}, F1: {best_f1:.4f}\")\n",
        "    return best_model, best_params\n"
      ],
      "metadata": {
        "id": "AmkzU5dSNyru"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded=files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "kcEwDRzXYI_5",
        "outputId": "7b05e3d7-335e-4f92-eb6d-aa0a67197dd9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-48786407-0e4e-42b1-b3f2-1230b42e10a6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-48786407-0e4e-42b1-b3f2-1230b42e10a6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving mrmr_selected_train_dmc1_esm_50.csv to mrmr_selected_train_dmc1_esm_50.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"mrmr_selected_train_dmc1_esm_50.csv\")\n",
        "weights=compute_sample_weights(df)"
      ],
      "metadata": {
        "id": "VLGB5pY0_VUy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Prepare data ----\n",
        "# Assume df is already loaded and sample_weights computed\n",
        "id_col = df.columns[0]\n",
        "feature_cols = df.columns[1:-2]\n",
        "label_col = df.columns[-1]\n",
        "taxa_col = df.columns[-2]\n",
        "\n",
        "X_train = df[feature_cols].values\n",
        "y_train = df[label_col].values\n",
        "sample_weights = compute_sample_weights(df, label_col=label_col, taxa_col=taxa_col).values"
      ],
      "metadata": {
        "id": "zEXgVTEeBpM1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Train model with CV ----\n",
        "model, best_params = tune_mlp_hyperparameters(X_train, y_train, sample_weights)"
      ],
      "metadata": {
        "id": "5wGjcB4GYlNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best parameters from the trained model recorded\n",
        "best_params = {\n",
        "    'hidden_dim': 128,\n",
        "    'dropout': 0.3,\n",
        "    'lr': 0.001,\n",
        "    'batch_size': 32,\n",
        "    'num_layers': 2,\n",
        "    'activation': 'relu',\n",
        "    'weight_decay': 0,\n",
        "    'optimizer': 'adamW'\n",
        "}"
      ],
      "metadata": {
        "id": "j2jsc3j8Xhvi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Prepare Dataset ---\n",
        "class ProteinDataset(Dataset):\n",
        "    def __init__(self, X, y, sample_weights):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "        self.sample_weights = torch.tensor(sample_weights, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx], self.sample_weights[idx]"
      ],
      "metadata": {
        "id": "Bv0JO8ZYVBKN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128, num_layers=1, dropout=0.3, activation='relu'):\n",
        "        super(MLPClassifier, self).__init__()\n",
        "\n",
        "        # Activation function\n",
        "        activations = {\n",
        "            'relu': nn.ReLU(),\n",
        "            'tanh': nn.Tanh(),\n",
        "            'sigmoid': nn.Sigmoid(),\n",
        "            'leaky_relu': nn.LeakyReLU(),\n",
        "            'elu': nn.ELU()\n",
        "        }\n",
        "        self.activation = activations.get(activation.lower(), nn.ReLU())\n",
        "\n",
        "        # Input layer\n",
        "        layers = [nn.Linear(input_dim, hidden_dim), self.activation, nn.Dropout(dropout)]\n",
        "\n",
        "        # Hidden layers\n",
        "        for _ in range(num_layers - 1):\n",
        "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "            layers.append(self.activation)\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "\n",
        "        # Output layer (2 for binary classification logits)\n",
        "        layers.append(nn.Linear(hidden_dim, 2))\n",
        "\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "0jqulQXDZj5T"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final model with best hyperparameters built\n",
        "best_model = MLPClassifier(\n",
        "    input_dim=X_train.shape[1],\n",
        "    hidden_dim=best_params['hidden_dim'],\n",
        "    dropout=best_params['dropout'],\n",
        "    num_layers=best_params['num_layers'],\n",
        "    activation=best_params['activation']\n",
        ").to(device)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.AdamW(\n",
        "    best_model.parameters(),\n",
        "    lr=best_params['lr'],\n",
        "    weight_decay=best_params['weight_decay']\n",
        ")\n",
        "\n",
        "# --- 6. Prepare data ---\n",
        "df_train = pd.read_csv(\"mrmr_selected_train_dmc1_esm_50.csv\")\n",
        "sample_weights = compute_sample_weights(df_train)  # Pass your training dataframe here\n",
        "train_dataset = ProteinDataset(X_train, y_train, sample_weights)\n",
        "train_loader = DataLoader(train_dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
        "\n",
        "# --- 7. Train with weighted loss ---\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    best_model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    for batch_x, batch_y, batch_w in train_loader:\n",
        "        batch_x, batch_y, batch_w = batch_x.to(device), batch_y.to(device), batch_w.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logits = best_model(batch_x)\n",
        "\n",
        "        # Compute per-sample losses\n",
        "        losses = F.cross_entropy(logits, batch_y, reduction='none')\n",
        "        weighted_loss = (losses * batch_w).mean()\n",
        "\n",
        "        weighted_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += weighted_loss.item()\n",
        "\n",
        "#    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")"
      ],
      "metadata": {
        "id": "csW-Kuc5IOc0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded=files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "n0sjZFU-Z_9B",
        "outputId": "b6a20636-3f16-4e22-8360-65f5fb5ebf7a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0769487a-d903-4686-a29c-adf4dff4ab88\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0769487a-d903-4686-a29c-adf4dff4ab88\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving mrmr_selected_test_dmc1_esm_50.csv to mrmr_selected_test_dmc1_esm_50.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare test set\n",
        "df_test = pd.read_csv(\"mrmr_selected_test_dmc1_esm_50.csv\")\n",
        "X_test = df_test.iloc[:, 1:-2].values  # features\n",
        "y_test = df_test.iloc[:, -1].values   # labels\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "\n",
        "# Predict\n",
        "best_model.eval()\n",
        "with torch.no_grad():\n",
        "    logits = best_model(X_test_tensor)\n",
        "    y_pred = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "\n",
        "# Evaluate\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "# print(\"✅ Accuracy: \", accuracy_score(y_test, y_pred))\n",
        "# print(\"✅ Precision:\", precision_score(y_test, y_pred))\n",
        "# print(\"✅ Recall:   \", recall_score(y_test, y_pred))\n",
        "# print(\"✅ F1 Score: \", f1_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "qsmXNFHwIS3D"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}