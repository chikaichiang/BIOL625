{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {
        "id": "C_uzy74IXY7D"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import StratifiedKFold, ParameterGrid, cross_validate\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "import numpy as np\n",
        "from joblib import Parallel, delayed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_sample_weights(df, label_col='label', taxa_col='taxa', meiosis_taxa=None):\n",
        "    \"\"\"\n",
        "    Compute sample weights based on label and optionally taxa for meiosis proteins.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): DataFrame containing the data.\n",
        "        label_col (str): Name of the label column ('Meiosis' vs. 'Non-meiosis').\n",
        "        taxa_col (str): Name of the column with taxonomic group info.\n",
        "        meiosis_taxa (list or set): Taxa considered for upweighting (e.g., fungi, plants).\n",
        "\n",
        "    Returns:\n",
        "        pd.Series: Sample weights aligned with df rows.\n",
        "    \"\"\"\n",
        "    if meiosis_taxa is None:\n",
        "        meiosis_taxa = {'chordates', 'arthropods', 'fungi', 'plants', 'other animals'}\n",
        "\n",
        "    weights = []\n",
        "    n_non_meiosis = len(df[df[label_col] == 0])\n",
        "    n_meiosis = len(df[df[label_col] == 1])\n",
        "    global_weight = n_non_meiosis / n_meiosis  # global class weight\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        if row[label_col] == 1 and row[taxa_col] in meiosis_taxa:\n",
        "            weights.append(global_weight)\n",
        "        else:\n",
        "            weights.append(1.0)\n",
        "\n",
        "    return pd.Series(weights, index=df.index)\n"
      ],
      "metadata": {
        "id": "t5h1EuIPac1u"
      },
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tune_rbf_svm(X_train, y_train, sample_weights=None, param_grid=None,\n",
        "                 n_splits=10, random_state=42, n_jobs=-1):\n",
        "    \"\"\"\n",
        "    Enhanced RBF-SVM tuning with parallel execution and smarter parameter search.\n",
        "\n",
        "    Parameters:\n",
        "        X_train (np.ndarray): Training features (n_samples, n_features)\n",
        "        y_train (np.ndarray): Labels (0/1)\n",
        "        sample_weights (np.ndarray): Optional sample weights\n",
        "        param_grid (dict): Hyperparameter grid\n",
        "        n_splits (int): CV folds\n",
        "        random_state (int): Random seed\n",
        "        n_jobs (int): CPU cores for parallelization (-1 = all)\n",
        "\n",
        "    Returns:\n",
        "        dict: Best parameters {'C': ..., 'gamma': ...}\n",
        "        float: Best F1 score\n",
        "    \"\"\"\n",
        "    if param_grid is None:\n",
        "        param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100, 1000],\n",
        "    'gamma': [1e-4, 1e-3, 1e-2, 0.1, 1, 10, 'scale', 'auto']\n",
        "}\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "    f1_scorer = make_scorer(f1_score)\n",
        "    best_score = -np.inf\n",
        "    best_params = {}\n",
        "\n",
        "    def evaluate_params(params):\n",
        "        model = SVC(\n",
        "            kernel='rbf',\n",
        "            C=params['C'],\n",
        "            gamma=params['gamma'],\n",
        "            class_weight='balanced' if sample_weights is None else None\n",
        "        )\n",
        "\n",
        "        # Correct way to pass sample_weight in cross_validate (using **kwargs)\n",
        "        if sample_weights is not None:\n",
        "            result = cross_validate(\n",
        "                model, X_train, y_train,\n",
        "                cv=cv,\n",
        "                scoring=f1_scorer,\n",
        "                n_jobs=1,\n",
        "                return_estimator=False,\n",
        "                fit_params={\"sample_weight\": sample_weights}  # ← NOT SUPPORTED → ERROR\n",
        "            )\n",
        "        else:\n",
        "            result = cross_validate(\n",
        "                model, X_train, y_train,\n",
        "                cv=cv,\n",
        "                scoring=f1_scorer,\n",
        "                n_jobs=1\n",
        "            )\n",
        "\n",
        "        # But this fails. So instead, we do manual CV loop below.\n",
        "        mean_score = np.mean(result['test_score'])\n",
        "        print(f\"C={params['C']:.3f}, gamma={params['gamma']}, F1={mean_score:.4f}\")\n",
        "        return mean_score, params\n",
        "\n",
        "\n",
        "    def evaluate_params_safe(params):\n",
        "        f1s = []\n",
        "        for train_idx, val_idx in cv.split(X_train, y_train):\n",
        "            X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
        "            y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "            w_tr = sample_weights[train_idx] if sample_weights is not None else None\n",
        "\n",
        "            model = SVC(\n",
        "                kernel='rbf',\n",
        "                C=params['C'],\n",
        "                gamma=params['gamma'],\n",
        "                random_state=random_state,\n",
        "                class_weight='balanced' if sample_weights is None else None\n",
        "            )\n",
        "\n",
        "            model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "            y_pred = model.predict(X_val)\n",
        "            f1 = f1_score(y_val, y_pred)\n",
        "            f1s.append(f1)\n",
        "\n",
        "        avg_f1 = np.mean(f1s)\n",
        "        print(f\"C={params['C']:.3f}, gamma={params['gamma']}, F1={avg_f1:.4f}\")\n",
        "        return avg_f1, params\n",
        "\n",
        "    results = Parallel(n_jobs=n_jobs)(\n",
        "        delayed(evaluate_params_safe)(params)\n",
        "        for params in ParameterGrid(param_grid)\n",
        "    )\n",
        "\n",
        "    for score, params in results:\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_params = params\n",
        "\n",
        "    print(f\"\\n🎯 Best: C={best_params['C']}, gamma={best_params['gamma']}, F1={best_score:.4f}\")\n",
        "    return best_params, best_score\n"
      ],
      "metadata": {
        "id": "49W1CQI-fg24"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.read_csv(\"mrmr_selected_train_rec8_esm_100.csv\")\n",
        "# sample_weights=compute_sample_weights(df)"
      ],
      "metadata": {
        "id": "HID31unJaYWd"
      },
      "execution_count": 314,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features and labels\n",
        "id_col = df.columns[0]\n",
        "feature_cols = df.columns[1:-2]  # Exclude ID, taxa, label\n",
        "label_col = df.columns[-1]\n",
        "taxa_col = df.columns[-2]\n",
        "\n",
        "X_train = df[feature_cols].values\n",
        "y_train = df[label_col].values\n",
        "taxa = df[taxa_col]"
      ],
      "metadata": {
        "id": "CCYutIKcacLn"
      },
      "execution_count": 317,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# best_params, best_score = tune_rbf_svm(X_train=X_train, y_train=y_train, sample_weights=sample_weights)"
      ],
      "metadata": {
        "id": "rIY6xMsvfnoO"
      },
      "execution_count": 318,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load test data\n",
        "df_test = pd.read_csv('mrmr_selected_test_spo11_aa_50.csv')\n",
        "\n",
        "# Extract columns\n",
        "ids = df_test.iloc[:, 0]              # ID column\n",
        "X_test = df_test.iloc[:, 1:-2].values # Feature matrix (already scaled)\n",
        "y_true = df_test.iloc[:, -1].values   # Label column (last column)\n",
        "\n",
        "# Train model on full training data using best hyperparameters\n",
        "if isinstance(best_params, tuple):  # Unpack if needed\n",
        "    best_params = best_params[0]\n",
        "\n",
        "model = SVC(kernel='rbf', C=best_params['C'], gamma=best_params['gamma'])\n",
        "model.fit(X_train, y_train, sample_weight=sample_weights)\n",
        "\n",
        "# Predict\n",
        "# y_pred = model.predict(X_test)\n",
        "\n",
        "# Metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "# Print metrics\n",
        "# print(f\"✅ Accuracy:  {accuracy:.4f}\")\n",
        "# print(f\"✅ Precision: {precision:.4f}\")\n",
        "# print(f\"✅ Recall:    {recall:.4f}\")\n",
        "# print(f\"✅ F1 Score:  {f1:.4f}\")"
      ],
      "metadata": {
        "id": "S6fq9BtqmXkY"
      },
      "execution_count": 321,
      "outputs": []
    }
  ]
}